{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:07:34.471816Z","iopub.status.busy":"2024-09-09T18:07:34.471356Z","iopub.status.idle":"2024-09-09T18:07:36.859004Z","shell.execute_reply":"2024-09-09T18:07:36.857236Z","shell.execute_reply.started":"2024-09-09T18:07:34.471767Z"},"trusted":true},"outputs":[],"source":["# Load necessar libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:07.231942Z","iopub.status.busy":"2024-09-09T18:09:07.231379Z","iopub.status.idle":"2024-09-09T18:09:07.291441Z","shell.execute_reply":"2024-09-09T18:09:07.290191Z","shell.execute_reply.started":"2024-09-09T18:09:07.231894Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>age</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>thalch</th>\n","      <th>oldpeak</th>\n","      <th>ca</th>\n","      <th>sex_0.0</th>\n","      <th>sex_1.0</th>\n","      <th>dataset_0.0</th>\n","      <th>...</th>\n","      <th>restecg_2.0</th>\n","      <th>exang_0.0</th>\n","      <th>exang_1.0</th>\n","      <th>slope_0.0</th>\n","      <th>slope_1.0</th>\n","      <th>slope_2.0</th>\n","      <th>thal_0.0</th>\n","      <th>thal_1.0</th>\n","      <th>thal_2.0</th>\n","      <th>num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>881</td>\n","      <td>62</td>\n","      <td>148.68</td>\n","      <td>170.00</td>\n","      <td>120.00</td>\n","      <td>3.000</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>458</td>\n","      <td>54</td>\n","      <td>150.00</td>\n","      <td>213.74</td>\n","      <td>122.00</td>\n","      <td>0.000</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>798</td>\n","      <td>51</td>\n","      <td>135.82</td>\n","      <td>339.00</td>\n","      <td>130.62</td>\n","      <td>3.066</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26</td>\n","      <td>50</td>\n","      <td>120.00</td>\n","      <td>219.00</td>\n","      <td>158.00</td>\n","      <td>1.600</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>85</td>\n","      <td>52</td>\n","      <td>120.00</td>\n","      <td>325.00</td>\n","      <td>172.00</td>\n","      <td>0.200</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 31 columns</p>\n","</div>"],"text/plain":["    id  age  trestbps    chol  thalch  oldpeak   ca  sex_0.0  sex_1.0  \\\n","0  881   62    148.68  170.00  120.00    3.000  1.0        0        1   \n","1  458   54    150.00  213.74  122.00    0.000  0.0        0        1   \n","2  798   51    135.82  339.00  130.62    3.066  2.0        0        1   \n","3   26   50    120.00  219.00  158.00    1.600  0.0        1        0   \n","4   85   52    120.00  325.00  172.00    0.200  0.0        0        1   \n","\n","   dataset_0.0  ...  restecg_2.0  exang_0.0  exang_1.0  slope_0.0  slope_1.0  \\\n","0            0  ...            1          0          1          1          0   \n","1            0  ...            0          1          0          0          0   \n","2            0  ...            0          0          1          0          1   \n","3            1  ...            0          1          0          0          1   \n","4            1  ...            0          1          0          0          0   \n","\n","   slope_2.0  thal_0.0  thal_1.0  thal_2.0  num  \n","0          0         0         0         1    1  \n","1          1         0         0         1    0  \n","2          0         0         0         1    1  \n","3          0         0         1         0    0  \n","4          1         0         1         0    0  \n","\n","[5 rows x 31 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#Loading the heart_disease_uci dataset\n","train_data = pd.read_csv('..\\data\\heart_disease\\data_train.csv')\n","test_data = pd.read_csv('..\\data\\heart_disease\\data_test.csv')\n","train_data.head()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:11.101110Z","iopub.status.busy":"2024-09-09T18:09:11.100663Z","iopub.status.idle":"2024-09-09T18:09:11.127511Z","shell.execute_reply":"2024-09-09T18:09:11.126234Z","shell.execute_reply.started":"2024-09-09T18:09:11.101068Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>age</th>\n","      <th>trestbps</th>\n","      <th>chol</th>\n","      <th>thalch</th>\n","      <th>oldpeak</th>\n","      <th>ca</th>\n","      <th>sex_0.0</th>\n","      <th>sex_1.0</th>\n","      <th>dataset_0.0</th>\n","      <th>...</th>\n","      <th>restecg_1.0</th>\n","      <th>restecg_2.0</th>\n","      <th>exang_0.0</th>\n","      <th>exang_1.0</th>\n","      <th>slope_0.0</th>\n","      <th>slope_1.0</th>\n","      <th>slope_2.0</th>\n","      <th>thal_0.0</th>\n","      <th>thal_1.0</th>\n","      <th>thal_2.0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>881</td>\n","      <td>62</td>\n","      <td>148.68</td>\n","      <td>170.00</td>\n","      <td>120.00</td>\n","      <td>3.000</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>458</td>\n","      <td>54</td>\n","      <td>150.00</td>\n","      <td>213.74</td>\n","      <td>122.00</td>\n","      <td>0.000</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>798</td>\n","      <td>51</td>\n","      <td>135.82</td>\n","      <td>339.00</td>\n","      <td>130.62</td>\n","      <td>3.066</td>\n","      <td>2.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>26</td>\n","      <td>50</td>\n","      <td>120.00</td>\n","      <td>219.00</td>\n","      <td>158.00</td>\n","      <td>1.600</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>85</td>\n","      <td>52</td>\n","      <td>120.00</td>\n","      <td>325.00</td>\n","      <td>172.00</td>\n","      <td>0.200</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>...</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 30 columns</p>\n","</div>"],"text/plain":["    id  age  trestbps    chol  thalch  oldpeak   ca  sex_0.0  sex_1.0  \\\n","0  881   62    148.68  170.00  120.00    3.000  1.0        0        1   \n","1  458   54    150.00  213.74  122.00    0.000  0.0        0        1   \n","2  798   51    135.82  339.00  130.62    3.066  2.0        0        1   \n","3   26   50    120.00  219.00  158.00    1.600  0.0        1        0   \n","4   85   52    120.00  325.00  172.00    0.200  0.0        0        1   \n","\n","   dataset_0.0  ...  restecg_1.0  restecg_2.0  exang_0.0  exang_1.0  \\\n","0            0  ...            0            1          0          1   \n","1            0  ...            1            0          1          0   \n","2            0  ...            1            0          0          1   \n","3            1  ...            1            0          1          0   \n","4            1  ...            1            0          1          0   \n","\n","   slope_0.0  slope_1.0  slope_2.0  thal_0.0  thal_1.0  thal_2.0  \n","0          1          0          0         0         0         1  \n","1          0          0          1         0         0         1  \n","2          0          1          0         0         0         1  \n","3          0          1          0         0         1         0  \n","4          0          0          1         0         1         0  \n","\n","[5 rows x 30 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["#Splitting the data into features and target\n","X_train = train_data.iloc[:,:-1]\n","y_train = train_data.iloc[:,-1]\n","\n","X_test = test_data.iloc[:,:-1]\n","y_test = test_data.iloc[:,-1]\n","X_train.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:13.662139Z","iopub.status.busy":"2024-09-09T18:09:13.661675Z","iopub.status.idle":"2024-09-09T18:09:13.697567Z","shell.execute_reply":"2024-09-09T18:09:13.695940Z","shell.execute_reply.started":"2024-09-09T18:09:13.662081Z"},"trusted":true},"outputs":[],"source":["#Scaling the data\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:32.848674Z","iopub.status.busy":"2024-09-09T18:09:32.848147Z","iopub.status.idle":"2024-09-09T18:09:32.858987Z","shell.execute_reply":"2024-09-09T18:09:32.857325Z","shell.execute_reply.started":"2024-09-09T18:09:32.848627Z"},"trusted":true},"outputs":[],"source":["# Convert to DataFrame for easier handling\n","train_data = pd.DataFrame(X_train)\n","train_data['target'] = y_train.values\n","\n","test_data = pd.DataFrame(X_test)\n","test_data['target'] = y_test.values\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:25:28.703666Z","iopub.status.busy":"2024-09-09T18:25:28.703025Z","iopub.status.idle":"2024-09-09T18:29:13.468396Z","shell.execute_reply":"2024-09-09T18:29:13.466833Z","shell.execute_reply.started":"2024-09-09T18:25:28.703614Z"},"trusted":true},"outputs":[{"ename":"ImportError","evalue":"tokenizers>=0.11.1,!=0.11.3,<0.14 is required for a normal functioning of this module, but found tokenizers==0.19.1.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-13-33cb63ced3d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load the Mistral model and tokenizer from Hugging Face\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"mistralai/Mistral-7B-v0.1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"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\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m from .utils import (\n\u001b[0;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\transformers\\dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# not required, check version only if installed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mrequire_version_core\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[1;34m(requirement)\u001b[0m\n","\u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[1;34m(requirement, hint)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;34m\"\"\"require_version wrapper which emits a core-specific hint on failure\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[0mhint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Try: `pip install transformers -U` or `pip install -e '.[dev]'` if you're working with git main\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\transformers\\utils\\versions.py\u001b[0m in \u001b[0;36m_compare_versions\u001b[1;34m(op, got_ver, want_ver, requirement, pkg, hint)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \"\"\"\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[0mPerform\u001b[0m \u001b[0ma\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdependency\u001b[0m \u001b[0mversions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mexact\u001b[0m \u001b[0msame\u001b[0m \u001b[0msyntax\u001b[0m \u001b[0mused\u001b[0m \u001b[0mby\u001b[0m \u001b[0mpip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mImportError\u001b[0m: tokenizers>=0.11.1,!=0.11.3,<0.14 is required for a normal functioning of this module, but found tokenizers==0.19.1.\nTry: pip install transformers -U or pip install -e '.[dev]' if you're working with git main"]}],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForCausalLM\n","\n","# Load the Mistral model and tokenizer from Hugging Face\n","model_name = \"mistralai/Mistral-7B-v0.1\"\n","token = \"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\"\n","\n","# Ensure compatibility by using AutoTokenizer and AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=token)\n","#model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, use_auth_token=token)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:29:13.473401Z","iopub.status.busy":"2024-09-09T18:29:13.471958Z","iopub.status.idle":"2024-09-09T18:29:13.986286Z","shell.execute_reply":"2024-09-09T18:29:13.984016Z","shell.execute_reply.started":"2024-09-09T18:29:13.473315Z"},"trusted":true},"outputs":[],"source":["# Tokenize the training data\n","def tokenize_row(row, tokenizer):\n","    row_str = \" \".join(map(str, row.values))\n","    inputs = tokenizer(row_str, padding='max_length', truncation=True, return_tensors=\"pt\")\n","    return inputs\n","\n","train_inputs = [tokenize_row(row, tokenizer) for _, row in train_data.iterrows()]\n","test_inputs = [tokenize_row(row, tokenizer) for _, row in test_data.iterrows()]\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:29:35.407723Z","iopub.status.busy":"2024-09-09T18:29:35.407117Z","iopub.status.idle":"2024-09-09T18:29:36.115020Z","shell.execute_reply":"2024-09-09T18:29:36.112320Z","shell.execute_reply.started":"2024-09-09T18:29:35.407668Z"},"trusted":true},"outputs":[],"source":["# Tokenize the training data\n","def tokenize_row(row, tokenizer):\n","    row_str = \" \".join(map(str, row.values))\n","    inputs = tokenizer(row_str, padding='max_length', truncation=True, return_tensors=\"pt\")\n","    return inputs\n","\n","train_inputs = [tokenize_row(row, tokenizer) for _, row in train_data.iterrows()]\n","test_inputs = [tokenize_row(row, tokenizer) for _, row in test_data.iterrows()]\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:29:40.084160Z","iopub.status.busy":"2024-09-09T18:29:40.082043Z","iopub.status.idle":"2024-09-09T18:29:40.104036Z","shell.execute_reply":"2024-09-09T18:29:40.101105Z","shell.execute_reply.started":"2024-09-09T18:29:40.084024Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class HeartDiseaseDataset(Dataset):\n","    def __init__(self, inputs, labels):\n","        self.inputs = inputs\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        input_ids = self.inputs[idx]['input_ids'].squeeze(0)\n","        attention_mask = self.inputs[idx]['attention_mask'].squeeze(0)\n","        label = torch.tensor(self.labels.iloc[idx])\n","        return input_ids, attention_mask, label\n","\n","# Create dataset and dataloader\n","train_dataset = HeartDiseaseDataset(train_inputs, y_train)\n","test_dataset = HeartDiseaseDataset(test_inputs, y_test)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:29:59.369318Z","iopub.status.busy":"2024-09-09T18:29:59.368450Z","iopub.status.idle":"2024-09-09T18:30:01.909025Z","shell.execute_reply":"2024-09-09T18:30:01.906212Z","shell.execute_reply.started":"2024-09-09T18:29:59.369240Z"},"trusted":true},"outputs":[],"source":["from transformers import AdamW\n","\n","# Set up the optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# Training function\n","def train(model, train_loader, optimizer):\n","    model.train()\n","    total_loss = 0\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = batch\n","        optimizer.zero_grad()\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","    return total_loss / len(train_loader)\n","\n","# Training loop\n","num_epochs = 3\n","for epoch in range(num_epochs):\n","    avg_loss = train(model, train_loader, optimizer)\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate(model, test_loader):\n","    model.eval()\n","    total_correct = 0\n","    total_examples = 0\n","    all_labels = []\n","    all_preds = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids, attention_mask, labels = batch\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            predictions = torch.argmax(outputs.logits, dim=-1)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(predictions.cpu().numpy())\n","            total_correct += (predictions == labels).sum().item()\n","            total_examples += labels.size(0)\n","    accuracy = total_correct / total_examples\n","    precision = precision_score(all_labels, all_preds)\n","    recall = recall_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds)\n","    return accuracy, precision, recall, f1\n","\n","# Evaluate the Mistral model\n","mistral_accuracy, mistral_precision, mistral_recall, mistral_f1 = evaluate(model, test_loader)\n","print(f'Mistral Model - Accuracy: {mistral_accuracy:.4f}, Precision: {mistral_precision:.4f}, Recall: {mistral_recall:.4f}, F1-Score: {mistral_f1:.4f}')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5670697,"sourceId":9354327,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
