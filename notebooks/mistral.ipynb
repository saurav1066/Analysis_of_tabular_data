{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:07:34.471816Z","iopub.status.busy":"2024-09-09T18:07:34.471356Z","iopub.status.idle":"2024-09-09T18:07:36.859004Z","shell.execute_reply":"2024-09-09T18:07:36.857236Z","shell.execute_reply.started":"2024-09-09T18:07:34.471767Z"},"trusted":true},"outputs":[],"source":["# Load necessar libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","import torch\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:07.231942Z","iopub.status.busy":"2024-09-09T18:09:07.231379Z","iopub.status.idle":"2024-09-09T18:09:07.291441Z","shell.execute_reply":"2024-09-09T18:09:07.290191Z","shell.execute_reply.started":"2024-09-09T18:09:07.231894Z"},"trusted":true},"outputs":[],"source":["#Loading the heart_disease_uci dataset\n","train_data = pd.read_csv('..\\data\\heart_disease\\data_train.csv')\n","test_data = pd.read_csv('..\\data\\heart_disease\\data_test.csv')\n","train_data.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:11.101110Z","iopub.status.busy":"2024-09-09T18:09:11.100663Z","iopub.status.idle":"2024-09-09T18:09:11.127511Z","shell.execute_reply":"2024-09-09T18:09:11.126234Z","shell.execute_reply.started":"2024-09-09T18:09:11.101068Z"},"trusted":true},"outputs":[],"source":["#Splitting the data into features and target\n","X_train = train_data.iloc[:,:-1]\n","y_train = train_data.iloc[:,-1]\n","\n","X_test = test_data.iloc[:,:-1]\n","y_test = test_data.iloc[:,-1]\n","X_train.head()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:13.662139Z","iopub.status.busy":"2024-09-09T18:09:13.661675Z","iopub.status.idle":"2024-09-09T18:09:13.697567Z","shell.execute_reply":"2024-09-09T18:09:13.695940Z","shell.execute_reply.started":"2024-09-09T18:09:13.662081Z"},"trusted":true},"outputs":[],"source":["#Scaling the data\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:09:32.848674Z","iopub.status.busy":"2024-09-09T18:09:32.848147Z","iopub.status.idle":"2024-09-09T18:09:32.858987Z","shell.execute_reply":"2024-09-09T18:09:32.857325Z","shell.execute_reply.started":"2024-09-09T18:09:32.848627Z"},"trusted":true},"outputs":[],"source":["# Convert to DataFrame for easier handling\n","train_data = pd.DataFrame(X_train)\n","train_data['target'] = y_train.values\n","\n","test_data = pd.DataFrame(X_test)\n","test_data['target'] = y_test.values\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:25:28.703666Z","iopub.status.busy":"2024-09-09T18:25:28.703025Z","iopub.status.idle":"2024-09-09T18:29:13.468396Z","shell.execute_reply":"2024-09-09T18:29:13.466833Z","shell.execute_reply.started":"2024-09-09T18:25:28.703614Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModelForCausalLM\n","\n","# Load the Mistral model and tokenizer from Hugging Face\n","model_name = \"mistralai/Mistral-7B-v0.1\"\n","token = \"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\"\n","\n","# Ensure compatibility by using AutoTokenizer and AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(model_name, token=token, device_map=\"auto\")\n","model = AutoModelForCausalLM.from_pretrained(model_name, num_labels=2,token=token,device_map=\"auto\")\n","\n","# Ensure pad_token_id is set\n","if tokenizer.pad_token_id is None:\n","    tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Modify the model for sequence classification\n","class MistralForClassification(torch.nn.Module):\n","    def __init__(self, model):\n","        super(MistralForClassification, self).__init__()\n","        self.model = model\n","        # Add a linear layer for classification (2 classes for heart disease)\n","        self.classifier = torch.nn.Linear(model.config.hidden_size, 2)\n","    \n","    def forward(self, input_ids, attention_mask=None, labels=None):\n","        # Get outputs from the Mistral model\n","        outputs = self.model(input_ids, attention_mask=attention_mask, output_hidden_states=False)\n","        \n","        # Take the hidden states (last layer) from the model's output\n","        logits = self.classifier(outputs.logits[:, -1, :])  # Classification on [CLS] token\n","        \n","        # Calculate loss if labels are provided\n","        loss = None\n","        if labels is not None:\n","            loss_fct = torch.nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, 2), labels.view(-1))\n","        \n","        return loss, logits\n","\n","# Initialize the model with the classification head\n","classification_model = MistralForClassification(model)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:29:40.084160Z","iopub.status.busy":"2024-09-09T18:29:40.082043Z","iopub.status.idle":"2024-09-09T18:29:40.104036Z","shell.execute_reply":"2024-09-09T18:29:40.101105Z","shell.execute_reply.started":"2024-09-09T18:29:40.084024Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Custom dataset class for PyTorch\n","class HeartDiseaseDataset(Dataset):\n","    def __init__(self, features, targets, tokenizer):\n","        self.features = features\n","        self.targets = targets\n","        self.tokenizer = tokenizer\n","    \n","    def __len__(self):\n","        return len(self.targets)\n","    \n","    def __getitem__(self, idx):\n","        # Convert row of features to string and tokenize\n","        row_str = \" \".join(map(str, self.features[idx]))\n","        inputs = self.tokenizer(row_str, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","        label = torch.tensor(self.targets[idx], dtype=torch.long)\n","        return inputs[\"input_ids\"].squeeze(0), inputs[\"attention_mask\"].squeeze(0), label\n","\n","\n","# Prepare dataset and dataloaders\n","train_dataset = HeartDiseaseDataset(X_train, y_train, tokenizer)\n","test_dataset = HeartDiseaseDataset(X_test, y_test, tokenizer)\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# defining a custom collate function to pad the sequences\n","from torch.nn.utils.rnn import pad_sequence\n","\n","def collate_fn(batch):\n","    input_ids = [item[0] for item in batch]\n","    attention_masks = [item[1] for item in batch]\n","    labels = [item[2] for item in batch]\n","\n","    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n","    attention_masks_padded = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n","    labels = torch.tensor(labels)\n","\n","    return input_ids_padded, attention_masks_padded, labels"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=2, collate_fn=collate_fn)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-09T18:29:59.369318Z","iopub.status.busy":"2024-09-09T18:29:59.368450Z","iopub.status.idle":"2024-09-09T18:30:01.909025Z","shell.execute_reply":"2024-09-09T18:30:01.906212Z","shell.execute_reply.started":"2024-09-09T18:29:59.369240Z"},"trusted":true},"outputs":[],"source":["from transformers import AdamW\n","import torch.nn.functional as F\n","\n","# Set up the optimizer\n","optimizer = AdamW(classification_model.parameters(), lr=5e-5)\n","\n","# Training function with gradient accumulation\n","def train(model, train_loader, optimizer, epochs=3, accumulation_steps=4):\n","    model.train()\n","    for epoch in range(epochs):\n","        total_loss = 0\n","        optimizer.zero_grad()\n","        for i, (input_ids, attention_mask, labels) in enumerate(train_loader):\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","            loss = outputs.loss\n","            total_loss += loss.item()\n","            loss.backward()\n","\n","            if (i + 1) % accumulation_steps == 0:\n","                optimizer.step()\n","                optimizer.zero_grad()\n","\n","        avg_loss = total_loss / len(train_loader)\n","        print(f\"Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n","\n","# Train the model with gradient accumulation\n","train(classification_model, train_loader, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to get predictions\n","def get_predictions(model, data_loader):\n","    model.eval()\n","    predictions = []\n","    for batch in data_loader:\n","        input_ids, attention_mask, labels = batch\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        _, pred = torch.max(outputs.logits, dim=1)\n","        predictions.extend(pred.tolist())\n","    return predictions\n","\n","# Get predictions on test set\n","test_predictions = get_predictions(classification_model, test_loader)\n","\n","# save predictions to results folder names bert.csv\n","pd.DataFrame(test_predictions).to_csv('results/mistral.csv', index=False)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate(model, test_loader):\n","    model.eval()\n","    total_correct = 0\n","    total_examples = 0\n","    all_labels = []\n","    all_preds = []\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            input_ids, attention_mask, labels = batch\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            predictions = torch.argmax(outputs.logits, dim=-1)\n","            all_labels.extend(labels.cpu().numpy())\n","            all_preds.extend(predictions.cpu().numpy())\n","            total_correct += (predictions == labels).sum().item()\n","            total_examples += labels.size(0)\n","    accuracy = total_correct / total_examples\n","    precision = precision_score(all_labels, all_preds)\n","    recall = recall_score(all_labels, all_preds)\n","    f1 = f1_score(all_labels, all_preds)\n","    return accuracy, precision, recall, f1\n","\n","# Evaluate the Mistral model\n","mistral_accuracy, mistral_precision, mistral_recall, mistral_f1 = evaluate(classifiication_model, test_loader)\n","print(f'Mistral Model - Accuracy: {mistral_accuracy:.4f}, Precision: {mistral_precision:.4f}, Recall: {mistral_recall:.4f}, F1-Score: {mistral_f1:.4f}')\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5670697,"sourceId":9354327,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
